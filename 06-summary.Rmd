# 总结展望 {#summary}

本文研究的重点是估计空间广义线性混合效应模型参数的算法，包括蒙特卡罗最大似然算法（简称MCML算法）、低秩近似算法（简称Low-Rank算法）、贝叶斯MCMC算法和贝叶斯STAN-MCMC算法。在相同设置下，比较了它们的性能，结论是MCML算法比Low-Rank算法收敛要慢很多，但是准确度比较它高，Low-Rank 可以增加采样点的数目快速接近MCML算法的精度，代价是运行时间会显著增加；基于Stan实现的贝叶斯STAN-MCMC算法比贝叶斯MCMC算法快很多，但是需要较多的计算机资源才能体现它的优势。目前，得益于计算机硬件的快速发展，无论是CPU还是GPU，甚至是谷歌专为机器学习量身打造的TPU也都进入量产了，分布式的多机并行算法一定是大规模数据集和复杂模型的出路，所以将可并行的传统算法用Stan重写是有实际应用价值的。

近年来，基于近似贝叶斯推断的算法也受到越来越多的关注，尤其是 INLA 算法(Integrated Nested Laplace Approximations)，因其高效的计算性能，快速发展的 INLA 社区^[<http://www.r-inla.org/>]，相关软件 R-INLA 的广泛使用和日益成熟的理论。将INLA算法和蒙特卡罗方法结合是值得研究的方向，Stan 程序库在 GPU 上的并行已经列入开发日程^[<https://github.com/stan-dev/stan/wiki/Longer-Term-To-Do-List>]，可以预见，将估计模型参数的算法基于Stan实现是快速提高计算效率的捷径。


<!-- 数据模拟和案例分析的部分，还可以增加响应变量服从指数族其它分布的情形，如泊松分布。算法性能的比较可以同时考虑时间和计算平台，记录多次运行同一个算法的时间数据，比较它们所耗时间的分布差异，可以获得更加可靠的结果。计算平台如多核，多线程，甚至集群环境的实现和比较，可以获得算法扩展性方面的结论。此外，不能单纯看算法实现的语言方式，从文中的计算结果来看，R 语言的性能是弱于 C++ （ Stan 是基于 C++ 的计算库，需要先编译源码和加载动态链接库）的，但是利用 R 编程可以快速实现算法原型。 INLA 算法和软件非常高效的表现，得益于随机偏微分方程已有的实现算法和近似手段，如三角网格划分，迭代格式让算法有更快的收敛速度，近似效果没有 MCML 和 Low-Rank 好。由此可知，算法的选择需要去做效果和效率的平衡， Stan 更新迭代的速度很快，可在不久的将来进入应用界，但是却也要求更多的学习成本和优化技巧。 -->


```{=latex}
\setlength{\bibsep}{0ex}
\bibliography{refer.bib,book.bib}
```
