# 总结与展望 {#summary}

本文重点研究了估计空间广义线性混合效应模型参数的算法，包括蒙特卡罗最大似然算法、低秩近似算法、贝叶斯 MCMC 算法和贝叶斯 Stan-HMC 算法。在相同设置下，模拟实验中贝叶斯 Stan-HMC 算法相比贝叶斯 MCMC 算法获得了很大的优势，在估计差不多的情形下，前者迭代次数比后者少很多，而且也不用复杂而耗时的调参，这对于实际应用很有帮助。但是 Stan 编程需要较多的技巧，不仅要熟悉统计模型，还需要了解模型编译的过程，特别是在发生错误和迭代不收敛的情况下，能够根据 Stan 提供的提示修改程序。空间广义线性混合效应模型的似然分析，包括拉普拉斯似然和蒙特卡罗似然都对参数初值比较敏感，结合剖面似然曲面分析是很重要的。

Rue 等 （2009 年） [@Rue2009] 提出集成嵌套拉普拉斯 （Integrated Nested Laplace Approximations，简称 INLA） 算法做近似贝叶斯推断，其广泛的适应性和高效性受到越来越多的关注，还有快速发展的 [INLA 社区][r-inla]，配套程序库 R-INLA 在不断的更新，基于这些因素，未来可以比较 INLA 和 Stan 在空间广义线性混合效应模型下的表现。 

贝叶斯方法的在近些年的兴起，离不开现代计算机的贡献，计算力越来越强劲，蒙特卡罗方法出现在越来越多的软件和程序库中，特别是 Stan，目前最新版的 Stan 已经具有一定的规模并行能力，这对于推动贝叶斯理论和应用是非常有帮助的。目前，Stan 程序库在 GPU 上的并行计算已经列入[开发日程][stan-todo-list]。


<!-- 算法和蒙特卡罗方法结合也是值得研究的方向 [@Virgilio2018]。 -->

<!-- 比较了它们的性能，结论是 MCML 算法比 Low-Rank 算法收敛要慢很多，但是准确度比较它高，Low-Rank 可以增加采样点的数目快速接近 MCML 算法的精度，代价是运行时间会显著增加；基于 Stan 实现的贝叶斯 Stan-HMC 算法比贝叶斯 MCMC 算法快很多，但是需要较多的计算机资源才能体现它的优势。目前，得益于计算机硬件的快速发展，无论是 CPU 还是 GPU，甚至是谷歌专为机器学习量身打造的 TPU 也都进入量产了，分布式的多机并行算法一定是大规模数据集和复杂模型的出路，所以将可并行的传统算法用 Stan 重写是有实际应用价值的。 -->

<!-- 数据模拟和案例分析的部分，还可以增加响应变量服从指数族其它分布的情形，如泊松分布。算法性能的比较可以同时考虑时间和计算平台，记录多次运行同一个算法的时间数据，比较它们所耗时间的分布差异，可以获得更加可靠的结果。计算平台如多核，多线程，甚至集群环境的实现和比较，可以获得算法扩展性方面的结论。此外，不能单纯看算法实现的语言方式，从文中的计算结果来看，R 语言的性能是弱于 C++ （ Stan 是基于 C++ 的计算库，需要先编译源码和加载动态链接库）的，但是利用 R 编程可以快速实现算法原型。 INLA 算法和软件非常高效的表现，得益于随机偏微分方程已有的实现算法和近似手段，如三角网格划分，迭代格式让算法有更快的收敛速度，近似效果没有 MCML 和 Low-Rank 好。由此可知，算法的选择需要去做效果和效率的平衡， Stan 更新迭代的速度很快，可在不久的将来进入应用界，但是却也要求更多的学习成本和优化技巧。 -->


```{=latex}
\setlength{\bibsep}{0ex}
\bibliography{latex/refer.bib,latex/book.bib}
```

[stan-todo-list]: https://github.com/stan-dev/stan/wiki/Longer-Term-To-Do-List
[r-inla]: http://www.r-inla.org/
